{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/FantasyFootballInjuryIQ/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-10-02 21:21:20.192850: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-02 21:21:20.209914: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-02 21:21:20.230519: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-02 21:21:20.236654: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-02 21:21:20.251844: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-02 21:21:21.525977: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import nfl_data_py as nfl\n",
    "import pandas as pd\n",
    "from NFL_Player import *\n",
    "from Injury import *\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from helperFunctions import *\n",
    "from googlesearch import search\n",
    "import re\n",
    "from datetime import datetime\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import injury_analysis\n",
    "\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:54.0) Gecko/20100101 Firefox/54.0',\n",
    "    'Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_1 like Mac OS X) AppleWebKit/603.1.30 (KHTML, like Gecko) Version/10.0 Mobile/14E304 Safari/602.1'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nflInjuries20 = nfl.import_injuries([2020])\n",
    "nflInjuries21 = nfl.import_injuries([2021])\n",
    "nflInjuries22 = nfl.import_injuries([2022])\n",
    "nflInjuries23 = nfl.import_injuries([2023])\n",
    "nflInjuries24 = nfl.import_injuries([2024])\n",
    "allNFLInjuries = pd.concat([nflInjuries20, nflInjuries21, nflInjuries22, nflInjuries23, nflInjuries24])\n",
    "\n",
    "max_season = max(allNFLInjuries[\"season\"])\n",
    "max_week = max(allNFLInjuries.loc[(allNFLInjuries[\"season\"] == max_season)][\"week\"])\n",
    "\n",
    "historicalNFLInjuries = allNFLInjuries.loc[(allNFLInjuries[\"season\"] != max_season) | (allNFLInjuries[\"week\"] != max_week)].copy()\n",
    "historicalNFLInjuries['InjuredInGame?'] = historicalNFLInjuries['practice_status'].apply(lambda x: x.strip() == \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def players_and_injuries_conversion_nfl(historicalNFLInjuries):\n",
    "    players = {}\n",
    "    for index, row in historicalNFLInjuries.iterrows():\n",
    "        keysList = list(players.keys())\n",
    "        temp_injury = GameInjuryReport(\n",
    "            row[\"season\"], \n",
    "            row[\"game_type\"], \n",
    "            row[\"team\"], \n",
    "            row[\"week\"], \n",
    "            row[\"report_primary_injury\"], \n",
    "            row[\"report_secondary_injury\"], \n",
    "            row[\"report_status\"], \n",
    "            row[\"practice_primary_injury\"], \n",
    "            row[\"practice_secondary_injury\"], \n",
    "            row[\"practice_status\"], \n",
    "            row[\"InjuredInGame?\"]\n",
    "        )\n",
    "\n",
    "        if row[\"full_name\"] not in keysList:\n",
    "            players[row[\"full_name\"]] = Player(row[\"first_name\"], row[\"last_name\"], row[\"position\"])\n",
    "        players.get(row[\"full_name\"]).add_injury(temp_injury)\n",
    "    return players\n",
    "\n",
    "def get_draft_sharks_url(first_name, last_name):\n",
    "    # Clean up names for URL generation\n",
    "    first_name_clean = ''.join(char for char in first_name if char.isalnum()).lower()\n",
    "    last_name_clean = ''.join(char for char in last_name if char.isalnum()).lower()\n",
    "    full_name = f\"{first_name} {last_name}\"\n",
    "    \n",
    "    # Prepare search query\n",
    "    search_query = f\"{full_name} Draft Sharks\"\n",
    "\n",
    "    # Maximum retries if rate-limited\n",
    "    max_retries = 5\n",
    "    retries = 0\n",
    "\n",
    "    # Start searching\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            # Rotate user-agent for each request\n",
    "            headers = {'User-Agent': random.choice(user_agents)}\n",
    "            \n",
    "            # Adding random sleep between 3 and 6 seconds before requests\n",
    "            random_sleep = random.uniform(3, 6)\n",
    "            print(f\"Waiting {random_sleep:.2f} seconds before making the search request...\")\n",
    "            time.sleep(random_sleep)\n",
    "\n",
    "            # Perform the search and look for the Draft Sharks URL\n",
    "            for url in search(search_query, num_results=10):\n",
    "                if 'draftsharks.com' in url:\n",
    "                    if f\"{first_name_clean}-{last_name_clean}\" in url:\n",
    "                        # Return the injury history URL if found\n",
    "                        if 'injury-history' in url:\n",
    "                            return url\n",
    "\n",
    "                        # If no injury history found, construct it using player ID\n",
    "                        match = re.search(r'/(\\d+)$', url)\n",
    "                        if match:\n",
    "                            player_id = match.group(1)\n",
    "                            return f\"https://www.draftsharks.com/fantasy/injury-history/{first_name_clean}-{last_name_clean}/{player_id}\"\n",
    "            break  # Exit if no URL found in this search cycle\n",
    "\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 429:  # Handle rate limit errors\n",
    "                wait_time = 2 ** retries + random.uniform(1, 3)  # Exponential backoff\n",
    "                print(f\"Rate limited. Retrying in {wait_time:.2f} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "                retries += 1  # Increment retry count\n",
    "            else:\n",
    "                print(f\"HTTP Error: {e}\")\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "    return None\n",
    "\n",
    "def add_draftsharks(player, url):\n",
    "# Maximum retries if rate-limited\n",
    "    max_retries = 5\n",
    "    retries = 0\n",
    "\n",
    "    # Start searching\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            print(f\"Adding Draftsharks Injuries For {player.first_name} {player.last_name}\")\n",
    "            print(f\"Try {retries}/{max_retries}\")\n",
    "            # Rotate user-agent for each request\n",
    "            headers = {'User-Agent': random.choice(user_agents)}\n",
    "            \n",
    "            # Adding random sleep between 3 and 6 seconds before requests\n",
    "            random_sleep = random.uniform(3, 6)\n",
    "            print(f\"Waiting {random_sleep:.2f} seconds before making the search request...\")\n",
    "            time.sleep(random_sleep)\n",
    "            print(\"Getting Response\")\n",
    "            response = requests.get(url, headers= headers)\n",
    "            print(\"Response Recieved\")\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            table_rows_container = soup.find(\"div\", class_=\"injury-history-table-container\")\n",
    "            if table_rows_container == None:\n",
    "                print(f\"No Container Response For {player.first_name} {player.last_name}\")\n",
    "                break\n",
    "            else:\n",
    "                table_rows_body = table_rows_container.find(\"tbody\")\n",
    "                if table_rows_body == None:\n",
    "                    print(f\"No Response For {player.first_name} {player.last_name}\")\n",
    "                    break\n",
    "                else:\n",
    "                    table_rows = table_rows_body.findAll(\"tr\")\n",
    "                    if table_rows == None:\n",
    "                        print(f\"No Response For {player.first_name} {player.last_name}\")\n",
    "                        break\n",
    "                    else:\n",
    "                        if len(table_rows) > 0:\n",
    "                            print(f\"Response Found For {player.first_name} {player.last_name}\")\n",
    "                        for row in table_rows:\n",
    "                            row_data = row.findAll(\"td\")\n",
    "                            injury_date = datetime.strptime(row_data[0].text, '%b %d, %Y')  # Date\n",
    "                            injury_league = row_data[1].text  # League\n",
    "                            injury = row_data[2].text  # Injury\n",
    "                            injury_details = row_data[3].text  # Description\n",
    "                            temp_injury = DetailedInjuryReport(injury_date, injury, injury_league, injury_details)\n",
    "                            player.add_injury(temp_injury)\n",
    "            break\n",
    "\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 429:  # Handle rate limit errors\n",
    "                wait_time = 2 ** retries + random.uniform(1, 3)  # Exponential backoff\n",
    "                print(f\"Rate limited. Retrying in {wait_time:.2f} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "                retries += 1  # Increment retry count\n",
    "            else:\n",
    "                raise Exception(f\"HTTP Error: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"An error occurred: {e}\")\n",
    "def players_and_injuries_conversion_draftsharks(player_name, player):\n",
    "    url = get_draft_sharks_url(player.first_name, player.last_name)\n",
    "    full_name = player_name\n",
    "    if url:\n",
    "        add_draftsharks(player, url)\n",
    "        print(f\"Draft Sharks URL for {full_name}: {url}\")\n",
    "    else:\n",
    "        print(f\"No Draft Sharks URL found for {full_name}.\")\n",
    "def split_dictionary(original_dict, chunk_size=450):\n",
    "    # Split the original dictionary into smaller chunks\n",
    "    keys = list(original_dict.keys())\n",
    "    chunks = [dict((k, original_dict[k]) for k in keys[i:i + chunk_size]) \n",
    "              for i in range(0, len(keys), chunk_size)]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = filterHistoricalNFLInjuries(historicalNFLInjuries, position=\"WR\")\n",
    "playersWithInjuries = players_and_injuries_conversion_nfl(historicalNFLInjuries)\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = {executor.submit(players_and_injuries_conversion_draftsharks, player_name, player): player_name for player_name, player in playersWithInjuries.items()}\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        player_name = futures[future]\n",
    "        try:\n",
    "            future.result()  # This will raise an exception if the thread raised one\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred for player {player_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "again = []\n",
    "\n",
    "# Wrap the playersWithInjuries dictionary with tqdm for progress tracking\n",
    "for player in tqdm(playersWithInjuries, desc=\"Processing Players\"):\n",
    "    if not any(isinstance(item, DetailedInjuryReport) for item in playersWithInjuries[player].injuries):\n",
    "        url = get_draft_sharks_url(playersWithInjuries[player].first_name, playersWithInjuries[player].last_name)\n",
    "        if url:\n",
    "            again.append(player)\n",
    "            print(f\"Draft Sharks URL for {player}: {url}\")\n",
    "        else:\n",
    "            print(f\"NO Draft Sharks URL for {player}\")\n",
    "print(len(again))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'Draft Sharks URL for [^:]+:\\s*(https:\\/\\/www\\.draftsharks\\.com\\/fantasy\\/injury-history\\/[^\\/]+\\/\\d+)'\n",
    "new_urls = [match for line in open('secondPass.txt') for match in re.findall(pattern, line) if match]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_chance = playersWithInjuries.copy()\n",
    "for i in tqdm(range(len(new_urls))):\n",
    "    print(second_chance[again[i]].injuries)\n",
    "    add_draftsharks(second_chance[again[i]], new_urls[i])\n",
    "    print(second_chance[again[i]].injuries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('playersWithInjuries9-30-24.pickle', 'wb') as handle:\n",
    "    pickle.dump(playersWithInjuries,handle,protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('second_chance10-1-24.pickle', 'rb') as handle:\n",
    "    second_chance = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Players: 100%|██████████| 2751/2751 [00:00<00:00, 57370.23it/s]\n"
     ]
    }
   ],
   "source": [
    "all_injuries = []\n",
    "for player in tqdm(second_chance, desc=\"Processing Players\"):\n",
    "        injury_dict = second_chance[player].to_dict()\n",
    "        for d in injury_dict:\n",
    "            all_injuries.append(d)\n",
    "\n",
    "all_injuries_df = pd.DataFrame(all_injuries)\n",
    "all_injuries_df = all_injuries_df.fillna('')\n",
    "# first_name\tlast_name\tposition    injury  report_secondary_injury\treport_status\tpractice_primary_injury\tpractice_secondary_injury\tpractice_status\tinjured_in_game\tdetails\n",
    "all_injuries_df['Combined'] = all_injuries_df.apply(lambda row: ' '.join(row.drop('injuries').drop('date').fillna('').astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('playersWithInjurie10-2-24.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_injuries_df,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
